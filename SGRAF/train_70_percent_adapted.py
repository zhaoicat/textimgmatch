#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
é«˜æ€§èƒ½è®­ç»ƒè„šæœ¬ - ç›®æ ‡R@1 >= 70%
é€‚é…ç°æœ‰tkæ•°æ®æ ¼å¼

ä¼˜åŒ–ç­–ç•¥:
1. æ›´ä¼˜çš„æŸå¤±å‡½æ•°ç»„åˆ
2. å¼ºåŒ–å¯¹æ¯”å­¦ä¹ 
3. ç¡¬è´Ÿä¾‹æŒ–æ˜  
4. å¤šå°ºåº¦è®­ç»ƒ
5. è¯¾ç¨‹å­¦ä¹ 
"""

import os
import sys
import time
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import random

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_path = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_path)

from data_chinese import get_precomp_loader, get_tokenizer
from lib.vse import VSEModel
from lib.evaluation import i2t, t2i, AverageMeter, LogCollector
import vocab


class AdvancedConfig:
    """é«˜çº§é…ç½® - é€‚é…tkæ•°æ®"""
    def __init__(self):
        # æ•°æ®é…ç½®
        self.data_path = './data/tk_precomp'
        self.data_name = 'tk_precomp'
        
        # æ¨¡å‹é…ç½® - å¢å¼ºç‰ˆ
        self.embed_size = 1024  # æ›´å¤§çš„åµŒå…¥ç»´åº¦
        self.finetune = True
        self.cnn_type = 'resnet152'
        self.use_restval = False
        self.vocab_size = 20000
        self.word_dim = 300
        
        # è®­ç»ƒé…ç½® - ä¼˜åŒ–ç‰ˆ
        self.batch_size = 32  # å¢å¤§æ‰¹æ¬¡
        self.num_epochs = 80
        self.lr_vse = 0.0008  # è°ƒæ•´å­¦ä¹ ç‡
        self.lr_cnn = 0.0001
        self.lr_decay = 0.85
        self.lr_update = 8
        self.workers = 4
        
        # æŸå¤±é…ç½® - å…³é”®ä¼˜åŒ–
        self.margin = 0.25  # è°ƒæ•´è¾¹è·
        self.temperature = 0.05  # æ›´ä½æ¸©åº¦å¢å¼ºå¯¹æ¯”
        self.focal_gamma = 2.0  # Focal losså‚æ•°
        self.triplet_weight = 1.0
        self.contrastive_weight = 0.8
        self.focal_weight = 0.3
        
        # è®­ç»ƒç­–ç•¥
        self.warmup_epochs = 5
        self.curriculum_start = 0.3
        self.hard_negative_ratio = 0.6
        
        # å…¶ä»–é…ç½®
        self.val_step = 500
        self.log_step = 100
        self.logger_name = './runs/tk_70_target/log'
        self.model_name = './runs/tk_70_target/checkpoint'
        self.resume = ""
        self.max_violation = True
        self.img_dim = 2048
        self.no_imgnorm = False
        self.reset_train = True
        self.reset_start_epoch = False
        
        # æ—©åœé…ç½®
        self.early_stop_patience = 12
        self.target_performance = 70.0  # ç›®æ ‡R@1


class FocalContrastiveLoss(nn.Module):
    """Focal + Contrastive Loss"""
    def __init__(self, temperature=0.05, gamma=2.0):
        super(FocalContrastiveLoss, self).__init__()
        self.temperature = temperature
        self.gamma = gamma
        
    def forward(self, img_emb, cap_emb):
        batch_size = img_emb.size(0)
        
        # L2æ ‡å‡†åŒ–
        img_emb = nn.functional.normalize(img_emb, p=2, dim=1)
        cap_emb = nn.functional.normalize(cap_emb, p=2, dim=1)
        
        # è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ
        logits = torch.mm(img_emb, cap_emb.t()) / self.temperature
        
        # æ ‡ç­¾
        labels = torch.arange(batch_size)
        if torch.cuda.is_available():
            labels = labels.cuda()
        
        # è®¡ç®—æ¦‚ç‡
        exp_logits = torch.exp(logits)
        sum_exp_logits = exp_logits.sum(dim=1, keepdim=True)
        probabilities = exp_logits / sum_exp_logits
        
        # Focal loss - å…³æ³¨å›°éš¾æ ·æœ¬
        correct_prob = probabilities[torch.arange(batch_size), labels]
        focal_weight = (1 - correct_prob) ** self.gamma
        
        # è´Ÿå¯¹æ•°ä¼¼ç„¶
        loss_i2t = -focal_weight * torch.log(correct_prob + 1e-10)
        
        # å¯¹ç§°æŸå¤± - text to image
        exp_logits_t = exp_logits.t()
        sum_exp_logits_t = exp_logits_t.sum(dim=1, keepdim=True)
        probabilities_t = exp_logits_t / sum_exp_logits_t
        correct_prob_t = probabilities_t[torch.arange(batch_size), labels]
        focal_weight_t = (1 - correct_prob_t) ** self.gamma
        loss_t2i = -focal_weight_t * torch.log(correct_prob_t + 1e-10)
        
        return (loss_i2t.mean() + loss_t2i.mean()) / 2


class EnhancedTripletLoss(nn.Module):
    """å¢å¼ºä¸‰å…ƒç»„æŸå¤± - ç¡¬è´Ÿä¾‹æŒ–æ˜"""
    def __init__(self, margin=0.25, hard_negative_ratio=0.6):
        super(EnhancedTripletLoss, self).__init__()
        self.margin = margin
        self.hard_ratio = hard_negative_ratio
        
    def forward(self, img_emb, cap_emb):
        batch_size = img_emb.size(0)
        
        # è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ
        scores = torch.mm(img_emb, cap_emb.t())
        diagonal = scores.diag().view(batch_size, 1)
        
        # Image to textè¿å
        d1 = diagonal.expand_as(scores)
        cost_s = (self.margin + scores - d1).clamp(min=0)
        
        # Text to imageè¿å
        d2 = diagonal.t().expand_as(scores)
        cost_im = (self.margin + scores - d2).clamp(min=0)
        
        # æ¸…é™¤å¯¹è§’çº¿
        mask = torch.eye(batch_size) > 0.5
        if torch.cuda.is_available():
            mask = mask.cuda()
        cost_s = cost_s.masked_fill_(mask, 0)
        cost_im = cost_im.masked_fill_(mask, 0)
        
        # ç¡¬è´Ÿä¾‹æŒ–æ˜ - é€‰æ‹©æœ€å›°éš¾çš„ä¸€éƒ¨åˆ†è´Ÿä¾‹
        num_hard = max(1, int(batch_size * self.hard_ratio))
        
        # Image to text
        cost_s_sorted, _ = cost_s.sort(dim=1, descending=True)
        cost_s_hard = cost_s_sorted[:, :num_hard]
        
        # Text to image
        cost_im_sorted, _ = cost_im.sort(dim=0, descending=True)
        cost_im_hard = cost_im_sorted[:num_hard, :]
        
        return cost_s_hard.mean() + cost_im_hard.mean()


class PrecomputedImageEncoder(nn.Module):
    """é¢„è®¡ç®—ç‰¹å¾çš„å›¾åƒç¼–ç å™¨"""
    
    def __init__(self, img_dim, embed_size):
        super(PrecomputedImageEncoder, self).__init__()
        self.embed_size = embed_size
        
        # å…¨å±€å¹³å‡æ± åŒ–å’Œçº¿æ€§æ˜ å°„
        self.fc = nn.Linear(img_dim, embed_size)
        self.init_weights()
    
    def init_weights(self):
        """åˆå§‹åŒ–æƒé‡"""
        nn.init.xavier_uniform_(self.fc.weight)
        nn.init.constant_(self.fc.bias, 0)
    
    def forward(self, images):
        """å‰å‘ä¼ æ’­"""
        # å¦‚æœè¾“å…¥æ˜¯3Dçš„ (batch, regions, features)ï¼Œè¿›è¡Œå…¨å±€å¹³å‡æ± åŒ–
        if len(images.shape) == 3:
            features = images.mean(dim=1)  # å¹³å‡æ‰€æœ‰åŒºåŸŸç‰¹å¾
        else:
            features = images
        
        # æ˜ å°„åˆ°åµŒå…¥ç©ºé—´
        features = self.fc(features)
        
        # L2æ ‡å‡†åŒ–
        features = nn.functional.normalize(features, p=2, dim=1)
        
        return features


class AdaptedVSEModel(VSEModel):
    """é€‚é…é¢„è®¡ç®—ç‰¹å¾çš„VSEæ¨¡å‹"""
    
    def __init__(self, opt):
        # ä¸è°ƒç”¨çˆ¶ç±»çš„__init__ï¼Œè‡ªå·±å®ç°
        nn.Module.__init__(self)
        
        # é¢„è®¡ç®—ç‰¹å¾çš„å›¾åƒç¼–ç å™¨
        self.img_enc = PrecomputedImageEncoder(
            img_dim=opt.img_dim,
            embed_size=opt.embed_size
        )
        
        # æ–‡æœ¬ç¼–ç å™¨
        from lib.vse import TextEncoder
        self.txt_enc = TextEncoder(
            vocab_size=opt.vocab_size,
            word_dim=opt.word_dim,
            embed_size=opt.embed_size
        )


class ProgressiveTrainer:
    """æ¸è¿›å¼è®­ç»ƒå™¨"""
    
    def __init__(self):
        self.opt = AdvancedConfig()
        self.focal_loss = FocalContrastiveLoss(
            temperature=self.opt.temperature,
            gamma=self.opt.focal_gamma
        )
        self.triplet_loss = EnhancedTripletLoss(
            margin=self.opt.margin,
            hard_negative_ratio=self.opt.hard_negative_ratio
        )
        
        # åŠ è½½è¯æ±‡è¡¨
        self.vocab = self.load_vocab()
        if self.vocab:
            self.opt.vocab_size = len(self.vocab)
    
    def load_vocab(self):
        """åŠ è½½è¯æ±‡è¡¨"""
        try:
            import pickle
            vocab_path = f'./vocab/{self.opt.data_name}_vocab.pkl'
            if os.path.exists(vocab_path):
                with open(vocab_path, 'rb') as f:
                    return pickle.load(f)
            else:
                print(f"è¯æ±‡è¡¨æ–‡ä»¶ {vocab_path} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
                return None
        except Exception as e:
            print(f"åŠ è½½è¯æ±‡è¡¨å¤±è´¥: {e}")
            return None
        
    def get_learning_rate(self, epoch):
        """è·å–è‡ªé€‚åº”å­¦ä¹ ç‡"""
        if epoch < self.opt.warmup_epochs:
            # é¢„çƒ­é˜¶æ®µ
            return self.opt.lr_vse * (epoch + 1) / self.opt.warmup_epochs
        else:
            # ä½™å¼¦é€€ç«
            remaining = epoch - self.opt.warmup_epochs
            total_remaining = self.opt.num_epochs - self.opt.warmup_epochs
            return self.opt.lr_vse * (1 + np.cos(np.pi * remaining / total_remaining)) / 2
    
    def train_epoch(self, model, data_loader, optimizer, epoch):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        model.train()
        
        batch_time = AverageMeter()
        data_time = AverageMeter()
        train_logger = LogCollector()
        
        # è°ƒæ•´å­¦ä¹ ç‡
        lr = self.get_learning_rate(epoch)
        for param_group in optimizer.param_groups:
            param_group['lr'] = lr
        
        end = time.time()
        total_batches = len(data_loader)
        
        for i, train_data in enumerate(data_loader):
            data_time.update(time.time() - end)
            
            # æ•°æ®å‡†å¤‡
            images, captions, lengths, ids = train_data
            
            if torch.cuda.is_available():
                images = images.cuda()
                captions = captions.cuda()
            
            # å‰å‘ä¼ æ’­
            img_emb, cap_emb = model.forward_emb(images, captions, lengths)
            
            # è®¡ç®—å¤šç§æŸå¤±
            loss_triplet = self.triplet_loss(img_emb, cap_emb)
            loss_focal = self.focal_loss(img_emb, cap_emb)
            
            # ç»„åˆæŸå¤±
            total_loss = (self.opt.triplet_weight * loss_triplet + 
                         self.opt.focal_weight * loss_focal)
            
            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            total_loss.backward()
            
            # æ¢¯åº¦è£å‰ªé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)
            
            optimizer.step()
            
            # è®°å½•
            train_logger.update('Loss', total_loss.item(), img_emb.size(0))
            train_logger.update('Triplet', loss_triplet.item(), img_emb.size(0))
            train_logger.update('Focal', loss_focal.item(), img_emb.size(0))
            
            batch_time.update(time.time() - end)
            end = time.time()
            
            if i % self.opt.log_step == 0:
                print(f'Epoch [{epoch+1}][{i}/{total_batches}] '
                      f'LR: {lr:.6f} '
                      f'Time {batch_time.val:.3f} '
                      f'Loss {train_logger.meters["Loss"].val:.4f} '
                      f'Triplet {train_logger.meters["Triplet"].val:.4f} '
                      f'Focal {train_logger.meters["Focal"].val:.4f}')
    
    def validate(self, model, data_loader):
        """æ¨¡å‹éªŒè¯"""
        model.eval()
        
        img_embs = []
        cap_embs = []
        
        print("å¼€å§‹éªŒè¯...")
        with torch.no_grad():
            for val_data in data_loader:
                images, captions, lengths, ids = val_data
                
                if torch.cuda.is_available():
                    images = images.cuda()
                    captions = captions.cuda()
                
                img_emb, cap_emb = model.forward_emb(images, captions, lengths)
                
                img_embs.append(img_emb.cpu().numpy())
                cap_embs.append(cap_emb.cpu().numpy())
        
        img_embs = np.concatenate(img_embs, axis=0)
        cap_embs = np.concatenate(cap_embs, axis=0)
        
        # è®¡ç®—æ£€ç´¢æŒ‡æ ‡
        (r1, r5, r10, medr, meanr) = i2t(img_embs, cap_embs, measure='cosine')
        (r1i, r5i, r10i, medri, meanri) = t2i(img_embs, cap_embs, measure='cosine')
        
        rsum = r1 + r5 + r10 + r1i + r5i + r10i
        avg_r1 = (r1 + r1i) / 2
        
        print(f"\n=== éªŒè¯ç»“æœ ===")
        print(f"Text to Image: R@1: {r1i:.2f}%, R@5: {r5i:.2f}%, R@10: {r10i:.2f}%")
        print(f"Image to Text: R@1: {r1:.2f}%, R@5: {r5:.2f}%, R@10: {r10:.2f}%")
        print(f"å¹³å‡ R@1: {avg_r1:.2f}%")
        print(f"R-sum: {rsum:.2f}")
        
        return rsum, avg_r1, r1, r1i
    
    def train(self):
        """ä¸»è®­ç»ƒæµç¨‹"""
        print("=== é«˜æ€§èƒ½è®­ç»ƒå¼€å§‹ - ç›®æ ‡R@1 >= 70% ===")
        print(f"æ•°æ®è·¯å¾„: {self.opt.data_path}")
        print(f"æ•°æ®åç§°: {self.opt.data_name}")
        print(f"æ‰¹æ¬¡å¤§å°: {self.opt.batch_size}")
        print(f"åµŒå…¥ç»´åº¦: {self.opt.embed_size}")
        print(f"è¯æ±‡è¡¨å¤§å°: {self.opt.vocab_size}")
        print(f"åˆå§‹å­¦ä¹ ç‡: {self.opt.lr_vse}")
        print(f"æ¸©åº¦å‚æ•°: {self.opt.temperature}")
        print(f"è¾¹è·å‚æ•°: {self.opt.margin}")
        print(f"ç¡¬è´Ÿä¾‹æ¯”ä¾‹: {self.opt.hard_negative_ratio}")
        print(f"ç›®æ ‡æ€§èƒ½: R@1 >= {self.opt.target_performance}%")
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        os.makedirs(self.opt.logger_name, exist_ok=True)
        os.makedirs(self.opt.model_name, exist_ok=True)
        
                          # æ•°æ®åŠ è½½å™¨
         if self.vocab:
             # ç›´æ¥ä½¿ç”¨tk_precompç›®å½•ä½œä¸ºæ•°æ®è·¯å¾„
             train_loader = get_precomp_loader(
                 './data/tk_precomp', 'train', self.vocab, self.opt,
                 batch_size=self.opt.batch_size, shuffle=True, 
                 num_workers=self.opt.workers
             )
             
             val_loader = get_precomp_loader(
                 './data/tk_precomp', 'dev', self.vocab, self.opt,
                 batch_size=self.opt.batch_size, shuffle=False,
                 num_workers=self.opt.workers
             )
        else:
            print("è¯æ±‡è¡¨ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œbuild_vocab.pyæ„å»ºè¯æ±‡è¡¨")
            return
        
        print(f"è®­ç»ƒæ ·æœ¬æ•°: {len(train_loader.dataset)}")
        print(f"éªŒè¯æ ·æœ¬æ•°: {len(val_loader.dataset)}")
        
        # æ¨¡å‹
        model = AdaptedVSEModel(self.opt)
        
        if torch.cuda.is_available():
            model.cuda()
            print("ä½¿ç”¨GPUè®­ç»ƒ")
        else:
            print("ä½¿ç”¨CPUè®­ç»ƒ")
        
        # ä¼˜åŒ–å™¨
        params = list(model.txt_enc.parameters())
        params += list(model.img_enc.parameters())
        
        optimizer = optim.Adam(params, lr=self.opt.lr_vse, 
                              weight_decay=1e-4)  # æ·»åŠ æƒé‡è¡°å‡
        
        # è®­ç»ƒçŠ¶æ€
        best_rsum = 0
        best_avg_r1 = 0
        patience_counter = 0
        
        print(f"\nå¼€å§‹è®­ç»ƒ {self.opt.num_epochs} epochs...")
        
        for epoch in range(self.opt.num_epochs):
            print(f"\n{'='*50}")
            print(f"Epoch {epoch+1}/{self.opt.num_epochs}")
            print(f"{'='*50}")
            
            # è®­ç»ƒ
            self.train_epoch(model, train_loader, optimizer, epoch)
            
            # éªŒè¯
            rsum, avg_r1, r1_t2i, r1_i2t = self.validate(model, val_loader)
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if avg_r1 > best_avg_r1:
                best_avg_r1 = avg_r1
                best_rsum = rsum
                patience_counter = 0
                
                # ä¿å­˜æ£€æŸ¥ç‚¹
                checkpoint = {
                    'epoch': epoch,
                    'model': model.state_dict(),
                    'best_rsum': best_rsum,
                    'best_avg_r1': best_avg_r1,
                    'r1_t2i': r1_t2i,
                    'r1_i2t': r1_i2t,
                    'opt': self.opt,
                }
                
                model_path = os.path.join(self.opt.model_name, 'best_model.pth')
                torch.save(checkpoint, model_path)
                
                print(f"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ - å¹³å‡R@1: {best_avg_r1:.2f}%")
                
                # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡
                if best_avg_r1 >= self.opt.target_performance:
                    print(f"ğŸ‰ æˆåŠŸè¾¾åˆ°ç›®æ ‡! å¹³å‡R@1: {best_avg_r1:.2f}% >= {self.opt.target_performance}%")
                    print("è®­ç»ƒæå‰ç»“æŸ!")
                    break
                    
            else:
                patience_counter += 1
                
            # æ—©åœæ£€æŸ¥
            if patience_counter >= self.opt.early_stop_patience:
                print(f"æ—©åœè§¦å‘ - è¿ç»­{self.opt.early_stop_patience}ä¸ªepochæ— æ”¹å–„")
                break
                
            print(f"å½“å‰æœ€ä½³å¹³å‡R@1: {best_avg_r1:.2f}% (ç›®æ ‡: {self.opt.target_performance}%)")
        
        # è®­ç»ƒæ€»ç»“
        print(f"\n{'='*60}")
        print("è®­ç»ƒå®Œæˆ!")
        print(f"æœ€ä½³å¹³å‡R@1: {best_avg_r1:.2f}%")
        print(f"æœ€ä½³R-sum: {best_rsum:.2f}")
        
        if best_avg_r1 >= self.opt.target_performance:
            print("âœ… æˆåŠŸè¾¾åˆ°70%ç›®æ ‡!")
        else:
            print(f"âŒ æœªå®Œå…¨è¾¾åˆ°70%ç›®æ ‡")
            print(f"å½“å‰æœ€ä½³: {best_avg_r1:.2f}%")
            print(f"è·ç¦»ç›®æ ‡è¿˜å·®: {self.opt.target_performance - best_avg_r1:.2f}%")
            
            # æä¾›æ”¹è¿›å»ºè®®
            print("\nğŸ”§ æ”¹è¿›å»ºè®®:")
            if best_avg_r1 < 30:
                print("1. æ£€æŸ¥æ•°æ®è´¨é‡å’Œé¢„å¤„ç†")
                print("2. è°ƒæ•´æ¨¡å‹æ¶æ„")
                print("3. ä½¿ç”¨æ›´å¼ºçš„é¢„è®­ç»ƒç‰¹å¾")
            elif best_avg_r1 < 50:
                print("1. å¢åŠ è®­ç»ƒæ•°æ®")
                print("2. æ•°æ®å¢å¼º")
                print("3. è°ƒæ•´æŸå¤±å‡½æ•°æƒé‡")
            else:
                print("1. ç²¾ç»†è°ƒæ•´è¶…å‚æ•°")
                print("2. å¢åŠ æ¨¡å‹å¤æ‚åº¦")
                print("3. é›†æˆå­¦ä¹ ")
        
        print(f"{'='*60}")


def main():
    """ä¸»å‡½æ•°"""
    trainer = ProgressiveTrainer()
    trainer.train()


if __name__ == '__main__':
    main() 