#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
é«˜æ€§èƒ½è®­ç»ƒ - ç›®æ ‡R@1 >= 70%
ä¼˜åŒ–ç­–ç•¥: Focal Loss + ç¡¬è´Ÿä¾‹æŒ–æ˜ + åŠ¨æ€å­¦ä¹ ç‡
"""

import os
import sys
import time
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader

from lib.datasets import RawImageDataset
from lib.vse import VSEModel
from data_chinese import get_tokenizer
from lib.evaluation import i2t, t2i, AverageMeter, LogCollector


class OptimizedConfig:
    """ä¼˜åŒ–é…ç½®"""
    def __init__(self):
        # æ•°æ®é…ç½®
        self.data_path = './data/tk'
        self.data_name = 'tk'
        
        # æ¨¡å‹é…ç½®
        self.embed_size = 1024  # æå‡åµŒå…¥ç»´åº¦
        self.finetune = True
        self.cnn_type = 'resnet152'
        self.use_restval = False
        
        # è®­ç»ƒé…ç½® - å…³é”®ä¼˜åŒ–
        self.batch_size = 24  # å¹³è¡¡å†…å­˜å’Œæ€§èƒ½
        self.num_epochs = 60
        self.lr_vse = 0.001  # æé«˜å­¦ä¹ ç‡
        self.lr_cnn = 0.0001
        self.lr_decay = 0.8
        self.lr_update = 8
        self.workers = 4
        
        # æŸå¤±å‡½æ•°é…ç½®
        self.margin = 0.2  # é™ä½è¾¹è·
        self.temperature = 0.03  # éå¸¸ä½çš„æ¸©åº¦
        self.focal_gamma = 2.5  # å¢å¼ºå›°éš¾æ ·æœ¬å…³æ³¨
        
        # è·¯å¾„é…ç½®
        self.val_step = 1000
        self.log_step = 50
        self.logger_name = './runs/tk_target_70/log'
        self.model_name = './runs/tk_target_70/checkpoint'
        self.resume = ""
        
        # å…¶ä»–é…ç½®
        self.max_violation = True
        self.img_dim = 2048
        self.no_imgnorm = False
        self.reset_train = True
        self.reset_start_epoch = False
        
        # æ—©åœå’Œç›®æ ‡
        self.early_stop_patience = 10
        self.target_r1 = 70.0


class FocalTripletLoss(nn.Module):
    """Focalå¢å¼ºçš„ä¸‰å…ƒç»„æŸå¤±"""
    def __init__(self, margin=0.2, gamma=2.5):
        super(FocalTripletLoss, self).__init__()
        self.margin = margin
        self.gamma = gamma
        
    def forward(self, im, s):
        batch_size = im.size(0)
        scores = torch.mm(im, s.t())
        diagonal = scores.diag().view(batch_size, 1)
        
        # Image to text
        d1 = diagonal.expand_as(scores)
        cost_s = (self.margin + scores - d1).clamp(min=0)
        
        # Text to image  
        d2 = diagonal.t().expand_as(scores)
        cost_im = (self.margin + scores - d2).clamp(min=0)
        
        # æ¸…é™¤å¯¹è§’çº¿
        mask = torch.eye(batch_size) > 0.5
        if torch.cuda.is_available():
            mask = mask.cuda()
        cost_s = cost_s.masked_fill_(mask, 0)
        cost_im = cost_im.masked_fill_(mask, 0)
        
        # Focal weighting - å¢å¼ºå›°éš¾æ ·æœ¬
        # å›°éš¾æ ·æœ¬çš„æŸå¤±æƒé‡æ›´é«˜
        focal_weight_s = (cost_s / (self.margin + 1e-8)) ** self.gamma
        focal_weight_im = (cost_im / (self.margin + 1e-8)) ** self.gamma
        
        cost_s = cost_s * focal_weight_s
        cost_im = cost_im * focal_weight_im
        
        # ç¡¬è´Ÿä¾‹æŒ–æ˜
        cost_s = cost_s.max(1)[0] 
        cost_im = cost_im.max(0)[0]
        
        return cost_s.sum() + cost_im.sum()


class AdvancedContrastiveLoss(nn.Module):
    """é«˜çº§å¯¹æ¯”æŸå¤±"""
    def __init__(self, temperature=0.03):
        super(AdvancedContrastiveLoss, self).__init__()
        self.temperature = temperature
        
    def forward(self, im, s):
        batch_size = im.size(0)
        
        # å¼ºåˆ¶æ ‡å‡†åŒ–
        im = nn.functional.normalize(im, p=2, dim=1)
        s = nn.functional.normalize(s, p=2, dim=1)
        
        # éå¸¸ä½æ¸©åº¦çš„ç›¸ä¼¼åº¦
        logits = torch.mm(im, s.t()) / self.temperature
        
        labels = torch.arange(batch_size)
        if torch.cuda.is_available():
            labels = labels.cuda()
        
        # åŒå‘äº¤å‰ç†µ
        loss_i2t = nn.CrossEntropyLoss()(logits, labels)
        loss_t2i = nn.CrossEntropyLoss()(logits.t(), labels)
        
        return (loss_i2t + loss_t2i) / 2


def train_epoch(model, data_loader, optimizer, epoch, opt, 
                focal_triplet_loss, contrastive_loss):
    """è®­ç»ƒä¸€ä¸ªepoch"""
    model.train()
    
    batch_time = AverageMeter()
    data_time = AverageMeter()
    train_logger = LogCollector()
    
    # åŠ¨æ€å­¦ä¹ ç‡è°ƒæ•´
    if epoch > 0 and epoch % opt.lr_update == 0:
        for param_group in optimizer.param_groups:
            param_group['lr'] *= opt.lr_decay
            print(f"å­¦ä¹ ç‡è°ƒæ•´ä¸º: {param_group['lr']:.6f}")
    
    end = time.time()
    total_batches = len(data_loader)
    
    for i, train_data in enumerate(data_loader):
        data_time.update(time.time() - end)
        
        # æ•°æ®å‡†å¤‡
        images, captions, lengths, ids = train_data
        
        if torch.cuda.is_available():
            images = images.cuda()
            captions = captions.cuda()
        
        # å‰å‘ä¼ æ’­
        img_emb, cap_emb = model.forward_emb(images, captions, lengths)
        
        # è®¡ç®—æŸå¤±
        loss_focal_triplet = focal_triplet_loss(img_emb, cap_emb)
        loss_contrastive = contrastive_loss(img_emb, cap_emb)
        
        # ç»„åˆæŸå¤± - é‡ç‚¹å…³æ³¨triplet loss
        total_loss = loss_focal_triplet + 0.6 * loss_contrastive
        
        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        total_loss.backward()
        
        # æ¢¯åº¦è£å‰ª
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=3.0)
        
        optimizer.step()
        
        # è®°å½•
        train_logger.update('Loss', total_loss.item(), img_emb.size(0))
        train_logger.update('FocalTriplet', loss_focal_triplet.item(), img_emb.size(0))
        train_logger.update('Contrastive', loss_contrastive.item(), img_emb.size(0))
        
        batch_time.update(time.time() - end)
        end = time.time()
        
        if i % opt.log_step == 0:
            current_lr = optimizer.param_groups[0]['lr']
            print(f'Epoch [{epoch+1}][{i}/{total_batches}] '
                  f'LR: {current_lr:.6f} '
                  f'Time {batch_time.val:.3f} '
                  f'Loss {train_logger.meters["Loss"].val:.4f} '
                  f'FT {train_logger.meters["FocalTriplet"].val:.4f} '
                  f'Cont {train_logger.meters["Contrastive"].val:.4f}')


def validate(model, data_loader):
    """éªŒè¯æ¨¡å‹"""
    model.eval()
    
    img_embs = []
    cap_embs = []
    
    print("éªŒè¯ä¸­...")
    with torch.no_grad():
        for val_data in data_loader:
            images, captions, lengths, ids = val_data
            
            if torch.cuda.is_available():
                images = images.cuda()
                captions = captions.cuda()
            
            img_emb, cap_emb = model.forward_emb(images, captions, lengths)
            
            img_embs.append(img_emb.cpu().numpy())
            cap_embs.append(cap_emb.cpu().numpy())
    
    img_embs = np.concatenate(img_embs, axis=0)
    cap_embs = np.concatenate(cap_embs, axis=0)
    
    # è®¡ç®—æ£€ç´¢æŒ‡æ ‡
    (r1, r5, r10, medr, meanr) = i2t(img_embs, cap_embs, measure='cosine')
    (r1i, r5i, r10i, medri, meanri) = t2i(img_embs, cap_embs, measure='cosine')
    
    rsum = r1 + r5 + r10 + r1i + r5i + r10i
    avg_r1 = (r1 + r1i) / 2
    
    print(f"\néªŒè¯ç»“æœ:")
    print(f"Text to Image: R@1: {r1i:.2f}%, R@5: {r5i:.2f}%, R@10: {r10i:.2f}%")
    print(f"Image to Text: R@1: {r1:.2f}%, R@5: {r5:.2f}%, R@10: {r10:.2f}%")
    print(f"å¹³å‡ R@1: {avg_r1:.2f}%")
    print(f"R-sum: {rsum:.2f}")
    
    return rsum, avg_r1, r1, r1i


def main():
    """ä¸»å‡½æ•°"""
    opt = OptimizedConfig()
    
    print("=" * 60)
    print("é«˜æ€§èƒ½è®­ç»ƒ - ç›®æ ‡R@1 >= 70%")
    print("=" * 60)
    print(f"æ‰¹æ¬¡å¤§å°: {opt.batch_size}")
    print(f"å­¦ä¹ ç‡: {opt.lr_vse}")
    print(f"åµŒå…¥ç»´åº¦: {opt.embed_size}")
    print(f"æ¸©åº¦å‚æ•°: {opt.temperature}")
    print(f"è¾¹è·å‚æ•°: {opt.margin}")
    print(f"Focal gamma: {opt.focal_gamma}")
    print(f"ç›®æ ‡: R@1 >= {opt.target_r1}%")
    print("=" * 60)
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(opt.logger_name, exist_ok=True)
    os.makedirs(opt.model_name, exist_ok=True)
    
    # æ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        RawImageDataset(opt.data_path, 'train', get_tokenizer()),
        batch_size=opt.batch_size, shuffle=True,
        num_workers=opt.workers, 
        collate_fn=RawImageDataset.collate_fn
    )
    
    val_loader = DataLoader(
        RawImageDataset(opt.data_path, 'dev', get_tokenizer()),
        batch_size=opt.batch_size, shuffle=False,
        num_workers=opt.workers, 
        collate_fn=RawImageDataset.collate_fn
    )
    
    print(f"è®­ç»ƒæ ·æœ¬: {len(train_loader.dataset)}")
    print(f"éªŒè¯æ ·æœ¬: {len(val_loader.dataset)}")
    
    # æ¨¡å‹
    model = VSEModel(opt)
    
    if torch.cuda.is_available():
        model.cuda()
        print("ä½¿ç”¨GPUè®­ç»ƒ")
    else:
        print("ä½¿ç”¨CPUè®­ç»ƒ")
    
    # æŸå¤±å‡½æ•°
    focal_triplet_loss = FocalTripletLoss(
        margin=opt.margin, 
        gamma=opt.focal_gamma
    )
    contrastive_loss = AdvancedContrastiveLoss(
        temperature=opt.temperature
    )
    
    # ä¼˜åŒ–å™¨
    params = list(model.txt_enc.parameters())
    params += list(model.img_enc.parameters())
    
    optimizer = optim.Adam(params, lr=opt.lr_vse, weight_decay=1e-5)
    
    # è®­ç»ƒçŠ¶æ€
    best_rsum = 0
    best_avg_r1 = 0
    patience_counter = 0
    
    print(f"\nå¼€å§‹è®­ç»ƒ {opt.num_epochs} epochs...")
    
    for epoch in range(opt.num_epochs):
        print(f"\nEpoch {epoch+1}/{opt.num_epochs}")
        print("-" * 50)
        
        # è®­ç»ƒ
        train_epoch(model, train_loader, optimizer, epoch, opt, 
                   focal_triplet_loss, contrastive_loss)
        
        # éªŒè¯
        rsum, avg_r1, r1_t2i, r1_i2t = validate(model, val_loader)
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if avg_r1 > best_avg_r1:
            best_avg_r1 = avg_r1
            best_rsum = rsum
            patience_counter = 0
            
            # ä¿å­˜æ£€æŸ¥ç‚¹
            checkpoint = {
                'epoch': epoch,
                'model': model.state_dict(),
                'best_rsum': best_rsum,
                'best_avg_r1': best_avg_r1,
                'opt': opt,
            }
            
            model_path = os.path.join(opt.model_name, 'best_model.pth')
            torch.save(checkpoint, model_path)
            
            print(f"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ - å¹³å‡R@1: {best_avg_r1:.2f}%")
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡
            if best_avg_r1 >= opt.target_r1:
                print(f"ğŸ‰ æˆåŠŸè¾¾åˆ°ç›®æ ‡! R@1: {best_avg_r1:.2f}% >= {opt.target_r1}%")
                break
                
        else:
            patience_counter += 1
            
        # æ—©åœ
        if patience_counter >= opt.early_stop_patience:
            print(f"æ—©åœè§¦å‘ - {opt.early_stop_patience}ä¸ªepochæ— æ”¹å–„")
            break
            
        print(f"å½“å‰æœ€ä½³R@1: {best_avg_r1:.2f}% (ç›®æ ‡: {opt.target_r1}%)")
    
    # æœ€ç»ˆæ€»ç»“
    print(f"\n{'='*60}")
    print("è®­ç»ƒå®Œæˆ!")
    print(f"æœ€ä½³å¹³å‡R@1: {best_avg_r1:.2f}%")
    print(f"æœ€ä½³R-sum: {best_rsum:.2f}")
    
    if best_avg_r1 >= opt.target_r1:
        print("âœ… æˆåŠŸè¾¾åˆ°70%ç›®æ ‡!")
    else:
        print(f"âŒ æœªè¾¾åˆ°ç›®æ ‡ï¼Œå½“å‰: {best_avg_r1:.2f}%, å·®è·: {opt.target_r1 - best_avg_r1:.2f}%")
    
    print(f"{'='*60}")


if __name__ == '__main__':
    main() 