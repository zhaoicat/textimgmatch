#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ä¸­æ–‡å›¾æ–‡åŒ¹é…æ¨¡å‹ä½¿ç”¨ç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•åŠ è½½å’Œä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹
"""

import torch
import numpy as np
import pickle
import jieba
import os
import sys

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_path = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_path)

def load_model(model_path):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {model_path}")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(model_path):
        print(f"é”™è¯¯: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ {model_path}")
        return None, None
    
    try:
        # åŠ è½½æ£€æŸ¥ç‚¹
        checkpoint = torch.load(model_path, map_location='cpu')
        
        # è·å–é…ç½®å’Œæ¨¡å‹
        if 'opt' in checkpoint:
            opt = checkpoint['opt']
            model_state = checkpoint['model']
        else:
            # å¦‚æœæ˜¯ç›´æ¥ä¿å­˜çš„æ¨¡å‹
            print("æ£€æµ‹åˆ°ç›´æ¥ä¿å­˜çš„æ¨¡å‹æ–‡ä»¶")
            return checkpoint, None
            
        print(f"âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ")
        print(f"âœ“ è®­ç»ƒè½®æ¬¡: {checkpoint.get('epoch', 'æœªçŸ¥')}")
        print(f"âœ“ æœ€ä½³æ€§èƒ½: R@1 = {checkpoint.get('best_r1', 'æœªçŸ¥')}%")
        
        return model_state, opt
        
    except Exception as e:
        print(f"åŠ è½½æ¨¡å‹æ—¶å‡ºé”™: {e}")
        return None, None

def load_vocabulary(vocab_path):
    """åŠ è½½è¯æ±‡è¡¨"""
    print(f"æ­£åœ¨åŠ è½½è¯æ±‡è¡¨: {vocab_path}")
    
    try:
        if vocab_path.endswith('.pkl'):
            with open(vocab_path, 'rb') as f:
                vocab = pickle.load(f)
        elif vocab_path.endswith('.json'):
            import json
            with open(vocab_path, 'r', encoding='utf-8') as f:
                vocab_data = json.load(f)
            vocab = vocab_data
        else:
            print("ä¸æ”¯æŒçš„è¯æ±‡è¡¨æ ¼å¼")
            return None
            
        print(f"âœ“ è¯æ±‡è¡¨åŠ è½½æˆåŠŸï¼ŒåŒ…å« {len(vocab)} ä¸ªè¯æ±‡")
        return vocab
        
    except Exception as e:
        print(f"åŠ è½½è¯æ±‡è¡¨æ—¶å‡ºé”™: {e}")
        return None

def preprocess_text(text, vocab):
    """é¢„å¤„ç†ä¸­æ–‡æ–‡æœ¬"""
    # ä½¿ç”¨jiebaåˆ†è¯
    tokens = list(jieba.cut(text.strip()))
    
    # è½¬æ¢ä¸ºè¯æ±‡ID
    if hasattr(vocab, 'word2idx'):
        # Vocabularyå¯¹è±¡
        word2idx = vocab.word2idx
        caption = [word2idx.get(token, word2idx.get('<unk>', 1)) for token in tokens]
        caption = [word2idx.get('<start>', 0)] + caption + [word2idx.get('<end>', 2)]
    else:
        # å­—å…¸æ ¼å¼
        caption = [vocab.get(token, vocab.get('<unk>', 1)) for token in tokens]
        caption = [vocab.get('<start>', 0)] + caption + [vocab.get('<end>', 2)]
    
    return caption, len(caption)

def compute_similarity(image_features, text_features):
    """è®¡ç®—å›¾åƒå’Œæ–‡æœ¬ç‰¹å¾çš„ç›¸ä¼¼åº¦"""
    # å½’ä¸€åŒ–ç‰¹å¾
    image_features = torch.nn.functional.normalize(image_features, p=2, dim=-1)
    text_features = torch.nn.functional.normalize(text_features, p=2, dim=-1)
    
    # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
    similarity = torch.cosine_similarity(image_features, text_features, dim=-1)
    
    return similarity.item()

def demo_usage():
    """æ¼”ç¤ºæ¨¡å‹ä½¿ç”¨"""
    print("=== ä¸­æ–‡å›¾æ–‡åŒ¹é…æ¨¡å‹ä½¿ç”¨æ¼”ç¤º ===\n")
    
    # 1. æ£€æŸ¥å¯ç”¨çš„æ¨¡å‹æ–‡ä»¶
    model_paths = [
        "./runs/tk_targeted/checkpoint/best_model.pth",
        "./runs/tk_SGR/checkpoint/model_best.pth.tar",
    ]
    
    model_path = None
    for path in model_paths:
        if os.path.exists(path):
            model_path = path
            break
    
    if model_path is None:
        print("âŒ æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶")
        print("è¯·å…ˆè¿è¡Œè®­ç»ƒè„šæœ¬ç”Ÿæˆæ¨¡å‹")
        return
    
    print(f"ğŸ“ ä½¿ç”¨æ¨¡å‹æ–‡ä»¶: {model_path}")
    print(f"ğŸ“ æ–‡ä»¶å¤§å°: {os.path.getsize(model_path) / (1024*1024):.1f} MB\n")
    
    # 2. åŠ è½½æ¨¡å‹
    model_state, opt = load_model(model_path)
    if model_state is None:
        return
    
    # 3. åŠ è½½è¯æ±‡è¡¨
    vocab_paths = [
        "./vocab/tk_precomp_vocab.pkl",
        "./vocab/tk_precomp_vocab.json"
    ]
    
    vocab = None
    for vocab_path in vocab_paths:
        if os.path.exists(vocab_path):
            vocab = load_vocabulary(vocab_path)
            if vocab is not None:
                break
    
    if vocab is None:
        print("âŒ æœªæ‰¾åˆ°è¯æ±‡è¡¨æ–‡ä»¶")
        return
    
    print()
    
    # 4. æ¼”ç¤ºæ–‡æœ¬é¢„å¤„ç†
    demo_texts = [
        "è¿™æ˜¯ä¸€å¹…ç¾ä¸½çš„å”å¡ç”»",
        "ä½›æ•™è‰ºæœ¯ä½œå“",
        "ä¼ ç»Ÿè—æ—æ–‡åŒ–",
        "è‰²å½©ä¸°å¯Œçš„å®—æ•™ç”»"
    ]
    
    print("ğŸ”¤ æ–‡æœ¬é¢„å¤„ç†æ¼”ç¤º:")
    for text in demo_texts:
        caption, length = preprocess_text(text, vocab)
        print(f"åŸæ–‡: {text}")
        print(f"åˆ†è¯: {list(jieba.cut(text))}")
        print(f"IDåºåˆ—: {caption[:10]}... (é•¿åº¦: {length})")
        print()
    
    # 5. æ¨¡æ‹Ÿç‰¹å¾è®¡ç®—
    print("ğŸ§® ç‰¹å¾ç›¸ä¼¼åº¦è®¡ç®—æ¼”ç¤º:")
    
    # æ¨¡æ‹Ÿå›¾åƒç‰¹å¾ (1024ç»´)
    image_feature = torch.randn(1024)
    
    # æ¨¡æ‹Ÿæ–‡æœ¬ç‰¹å¾ (1024ç»´)  
    text_feature = torch.randn(1024)
    
    # è®¡ç®—ç›¸ä¼¼åº¦
    similarity = compute_similarity(image_feature, text_feature)
    print(f"å›¾åƒç‰¹å¾ç»´åº¦: {image_feature.shape}")
    print(f"æ–‡æœ¬ç‰¹å¾ç»´åº¦: {text_feature.shape}")
    print(f"ç›¸ä¼¼åº¦åˆ†æ•°: {similarity:.4f}")
    print()
    
    # 6. ä½¿ç”¨è¯´æ˜
    print("ğŸ“– æ¨¡å‹ä½¿ç”¨è¯´æ˜:")
    print("1. å›¾åƒç‰¹å¾: éœ€è¦é¢„æå–ä¸º (36, 2048) çš„åŒºåŸŸç‰¹å¾")
    print("2. æ–‡æœ¬å¤„ç†: ä½¿ç”¨jiebaåˆ†è¯ï¼Œè½¬æ¢ä¸ºè¯æ±‡IDåºåˆ—")
    print("3. æ¨¡å‹æ¨ç†: é€šè¿‡SGRAFæ¨¡å‹ç¼–ç å¾—åˆ°ç‰¹å¾å‘é‡")
    print("4. ç›¸ä¼¼åº¦è®¡ç®—: ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦åŒ¹é…å›¾æ–‡")
    print()
    
    print("âœ… æ¼”ç¤ºå®Œæˆï¼")
    print(f"ğŸ“ æœ€ä½³æ¨¡å‹ä½ç½®: {model_path}")
    print("ğŸ“š è¯¦ç»†ä½¿ç”¨æ–¹æ³•è¯·å‚è€ƒ 'æœ€ç»ˆéªŒè¯æ€»ç»“æŠ¥å‘Š.md'")

if __name__ == "__main__":
    demo_usage() 